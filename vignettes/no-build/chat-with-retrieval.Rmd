---
title: "Chat with Retrieval"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Chat with Retrieval}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center"
)
```

## Introduction

The most powerful feature of `gpttools` is the `Chat with Retrieval` app. This app allows you to use the AI service of your choosing and augment chat with retrieval-based responses. This vignette will walk you through the process of using the app. This vignette assumes that you have already installed the package and set up your API key. With the app and API key in place, you are ready to create an index to use with the app. The typical patter is to use the `crawl()` function to create an index.

Let's use an example of creating an index from the extremely popular [R for Data Science](https://r4ds.hadley.nz/) book. Weâ€™ll use the `crawl()` function to scrape the text from the book using `{rvest}` under the hood to scrape the text from the online book. The text is then split into chunks with an associated embedding vector. The embedding vector is used to find similar chunks of text. The chunks of text are then stored in a parquet file for later use. For more on embeddings, see this fantastic resource from [Vicky Boykis](https://vickiboykis.com): [What are embeddings?](https://vickiboykis.com/what_are_embeddings/).

```{r}
#| eval: false
library(gpttools)
crawl("https://r4ds.hadley.nz/")
```

The code to scrape the data is relatively simple but is unlikely to work on all sites. From some internal testing, it works quite well on `{pkgdown}` and similar documentation sites.

## Using the app

![Chat with Retrieval app](images/chat-with-retrieval-app.png){width=75%}

Now that you have created an index, you are ready to use the app. The app is available via the `chat_with_retrieval()` function or the RStudio addin `Chat with Retrieval`. 

![Simple Example of Chat with Retrieval](images/chat-with-retrieval-example.gif){width=75%}

## Custom Settings

You can customize the app using the built-in settings popover. Settings include:

**Data & Task** 

- **Data Source**: The index or indices to use with the app. You can select multiple indices to use with the app. Default is "All" which uses all available indices.
- **Task**: The default is "Permissive Chat" which will tell you when it's missing context but still gives you an answer. The other option is "Strict Chat" which will only give you an answer if it has the context.

**Preferences**

- **AI Service**: The AI service to use with the app. The default is OpenAI, but you can also use HuggingFace, Google AI Studio, Anthropic, and more. **Note**: you must setup each service separately with your own account information and API key.
- **Model**: The model to use with the AI service. The default is "gpt-4-1106-preview" which is the most powerful model available from OpenAI.
- **Save & User History**: The default is FALSE. If TRUE, the app will save your chat history and allow you to use it as context for future chats.
- **Local Embeddings**: The default is TRUE that will download and use a model locally. If FALSE, OpenAI's API will be used to generate embeddings.
- **Docs to Include (#)**: The default is 4 which will include the top 4 most similar documents. You can increase or decrease this number as needed.
- **Chat History to Include (#)**: The default is 4 which will include the top 4 most similar chat history items. You can increase or decrease this number as needed.

Click `Save Settings` to save your settings across sessions.


![Customize Settings for Chat with Retrieval](images/chat-with-retrieval-settings.gif){width=75%}
