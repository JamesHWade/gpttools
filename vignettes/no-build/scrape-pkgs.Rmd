---
title: "Scrape Package Sites"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Scrape Package Sites}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center"
)
```

A common use for RAG (Retrieval Augmented Generaation) is package documentation. There are two addins to help you create package indices to use with the "Chat with Retrieval" app. The "Select Packages" addin launches a Shiny app that allows you to select packages and save your selections. The "Scrape Packages" addin scrapes installed packages and creates indices to use with the "Chat with Retrieval" app.

## Select Packages

![Select Packages App](images/pkg-selector-app.png){width=75%}

The "Select Packages" addin launches a Shiny app that allows you to select packages and save your selections. The app is launched by executing the "Select Packages" addin. The addin is available in the RStudio Addins menu. A set of default packages are pre-selected. You can add or remove packages from the list. When you are done, click the "Save Selected Packages" button to save your selections. Only installed packages are available for selection.

## Scrape Packages

Run the scrape packages addin by executing the "Scrape Packages" addin. The addin is available in the RStudio Addins menu. The addin will scrape installed packages and create indices to use with the "Chat with Retrieval" app. The addin will prompt you for confirmation before proceeding. The scraping process will run in the background. You can continue working in RStudio while the scraping process runs. You can check on progress in the `Background Jobs` pane.

The addin _only_ allows for embeddings to be created using local models. If you want to use embeddings using OpenAI embeddings, you will need to run the `scrape_pkg_sites()` function directly. See the section on [Scraping Script](#scraping-script) for more details. The reason for this is two fold: 1. some initial testing shows that the time to create embeddings is comparable between local and OpenAI embeddings, and 2. the OpenAI embeddings incur a cost for each request. The cost is small, but it is not free.

### Scraping Script

Here is the script that runs when you execute the "Scrape Packages" addin. `options(repos = c(CRAN = "https://packagemanager.posit.co/all/latest"))` sets global options in the R environment. In this case, it sets the 'repos' option to a custom CRAN repository URL, "https://packagemanager.posit.co/all/latest". This is telling R to use a specific CRAN-like repository provided by Posit Package Manager for installing packages. Posit Package manager offers consistent and fast access to package downloads. `options("repos")` is simply retrieving the current setting of the 'repos' option. It doesn't change the system state but would print the 'repos' options to the console. `scrape_pkg_sites()` initiates the scraping of package information from the defined CRAN repository.

```{r}
#| eval: false
library(gpttools)
cli_inform("Scraping package sites and creating an index for each.")
options(repos = c(CRAN = "https://packagemanager.posit.co/all/latest"))
options("repos")
scrape_pkg_sites()
```

`scrape_pkg_sites()` function is a scraping orchestrator that checks for packages to scrape, prompts for user confirmation, and then carries out the scraping operations by delegating to a helper function. The packages to scrape are determined by the `get_pkgs_to_scrape()` function. This function checks for packages that are installed but not yet scraped. If there are no packages to scrape, the function returns a message to the user. If there are packages to scrape, the function prompts the user for confirmation. If the user confirms, the function calls the `scrape_pkg_site()` function to scrape the package site.

Here are the default packages that will be scraped.

```{r}
#| echo: false
gpttools:::use_default_pkgs()
```
