% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/harvest-docs.R
\name{crawl}
\alias{crawl}
\title{Scrape and process all hyperlinks within a given URL}
\usage{
crawl(url, index_create = FALSE)
}
\arguments{
\item{url}{A character string with the URL to be scraped.}
}
\value{
NULL. The resulting tibble is saved into a parquet file.
}
\description{
This function scrapes all hyperlinks within a given URL and processes the
data into a tibble format. It saves the resulting tibble into a parquet file.
}
